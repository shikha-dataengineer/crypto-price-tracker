# Cryptocurrency Price Analysis Pipeline on Google Cloud

## Overview
This project implements an automated ETL pipeline to load, clean, and visualize real-time cryptocurrency price data using Google Cloud Platform (GCP) tools like **Cloud Storage**, **BigQuery**, and **Looker Studio**.

## Dataset Overview
The dataset contains historical OHLC (Open, High, Low, Close) price data for over 50 cryptocurrencies from **May 2013 to October 2022** on a daily basis. Prices are represented in USD. The data is stored in CSV format for fast and efficient loading.

You can find the original dataset on Kaggle here:  
[Crypto Price Prediction Dataset by shashwat1001](https://www.kaggle.com/code/shashwat1001/crypto-price-prediction)

## Data Description

| Column       | Description                                                                                  |
|--------------|----------------------------------------------------------------------------------------------|
| `open`       | Opening price on the date (UTC time)                                                        |
| `high`       | Highest price reached on the date (UTC time)                                                |
| `low`        | Lowest price reached on the date (UTC time)                                                 |
| `close`      | Closing price on the date (UTC time)                                                        |
| `volume`     | Quantity of asset bought or sold, in base currency                                          |
| `marketCap`  | Total market value of all coins mined (coins in circulation Ã— current coin price)           |
| `timestamp`  | UTC timestamp representing the day                                                          |
| `crypto_name`| Name of the cryptocurrency                                                                  |
| `date`       | Date derived from the timestamp                                                             |


## Project Overview
1. Source: Historical crypto price data from Kaggle
2. Objective: Build a clean, analytics-ready dataset for crypto market trends
3. Tools used:
  - Google Cloud Storage (GCS)
  - BigQuery (SQL transforms & storage)
  - Python (ETL orchestration)
  - Looker Studio (Visualization)

## ETL Pipeline Overview

### 1. **Data Ingestion**
- CSV uploaded to:  
  `gs://crypto-price-csv-bucket-2025/crypto_dataset.csv`
- Loaded into BigQuery table:  
  `crypto_analytics.final_crypto_prices`

### 2. **Data Transformation**
- Applied SQL cleaning via `bigquery/transform_query.sql`:
  - Parsed `timestamp` into `date` and `time`
  - Checked `NULL` rows if any
  - Deduplicated by `crypto_name + date`
  - Created clean, partitioned final table for querying
 
### 3. **Visualized results in Looker Studio**
   - Connected to BigQuery table: `crypto_analytics.cleaned_crypto_prices`
   - Created charts:
     - ðŸ“ˆ Line chart of `close` price over time
     - ðŸ“Š Bar chart of `volume` by `crypto_name`
     - ðŸ’° Line chart of Market Cap trend
     - ðŸ¥§ Pie chart Market share by Market cap
     - âœ¨ Scatter Plot for Volume vs Market cap

## Result
Created a reusable, scalable pipeline for financial data analytics using GCP.

### 4. **ETL Automation**
- Script: [`etl/etl_pipeline.py`](etl/etl_pipeline.py)

## How to Run
Run the ETL pipeline with:

```bash
python etl/etl_pipeline.py


